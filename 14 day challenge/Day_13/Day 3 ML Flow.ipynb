{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e73f2e47-63f5-4366-8280-20f51304e7fe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# ML Flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "51c3ad8b-c8ff-464c-8de6-7f4da320bf3d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Building Vector Assembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "86dca079-5a20-438b-861c-d16e34abf0e1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "# Prep the features (similar to before, but adding the new label)\n",
    "feature_cols = [\"total_views\",  \"v2p_rate\",  \"price_mean\"]\n",
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e66198e4-12f6-4686-99fb-be2a400ad7a8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "ML Model (GBT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "210a6b74-f8e2-41a4-a64f-145aa8b88163",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Cell 29"
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier, GBTClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "from mlflow.models.signature import infer_signature\n",
    "\n",
    "# 1. Clean Split (Passing raw data)\n",
    "X_train, X_test = df_final_prep.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# 2. Define the Candidates\n",
    "classifiers = [\n",
    "    LogisticRegression(labelCol=\"is_top_seller\", featuresCol=\"features\", maxIter=10),\n",
    "    RandomForestClassifier(labelCol=\"is_top_seller\", featuresCol=\"features\", numTrees=20),\n",
    "    GBTClassifier(labelCol=\"is_top_seller\", featuresCol=\"features\", maxIter=10)\n",
    "]\n",
    "\n",
    "# Use the volume path you defined earlier\n",
    "dfs_tmp_path = \"/Volumes/workspace/ecommerce/ecommerce_data\"\n",
    "\n",
    "# 3. The Tournament Loop\n",
    "for classifier in classifiers:\n",
    "    model_name = classifier.__class__.__name__\n",
    "    \n",
    "    with mlflow.start_run(run_name=model_name):\n",
    "        # A. Create and Train Pipeline\n",
    "        pipeline = Pipeline(stages=[assembler, classifier])\n",
    "        model = pipeline.fit(X_train)\n",
    "        \n",
    "        # B. Make Predictions\n",
    "        predictions = model.transform(X_test)\n",
    "        \n",
    "        # C. Generate Signature\n",
    "        input_example = X_test.select(feature_cols).limit(5).toPandas()\n",
    "        output_example = predictions.select(\"prediction\").limit(5).toPandas()\n",
    "        signature = infer_signature(input_example, output_example)\n",
    "        \n",
    "        # D. Calculate Metrics\n",
    "        evaluator_auc = BinaryClassificationEvaluator(labelCol=\"is_top_seller\", metricName=\"areaUnderROC\")\n",
    "        auc = evaluator_auc.evaluate(predictions)\n",
    "        \n",
    "        evaluator_f1 = MulticlassClassificationEvaluator(labelCol=\"is_top_seller\", metricName=\"f1\")\n",
    "        f1 = evaluator_f1.evaluate(predictions)\n",
    "        \n",
    "        # E. Log everything to MLflow\n",
    "        mlflow.log_param(\"model_type\", model_name)\n",
    "        mlflow.log_metric(\"auc\", auc)\n",
    "        mlflow.log_metric(\"f1_score\", f1)\n",
    "        \n",
    "        # FIXED LINE: Added dfs_tmpdir to comply with Unity Catalog requirements\n",
    "        mlflow.spark.log_model(\n",
    "            model, \n",
    "            \"model\", \n",
    "            signature=signature, \n",
    "            dfs_tmpdir=dfs_tmp_path\n",
    "        )\n",
    "        \n",
    "        print(f\"ðŸ† {model_name} -> AUC: {auc:.4f}, F1: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "92060e1d-58ba-4c27-995d-4932b408e68e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "# 1. Identify the best run programmatically\n",
    "best_run = mlflow.search_runs(\n",
    "    order_by=[\"metrics.f1_score DESC\"]\n",
    ").iloc[0]\n",
    "\n",
    "run_id = best_run.run_id\n",
    "model_uri = f\"runs:/{run_id}/model\"\n",
    "model_name = \"workspace.ecommerce.elite_product_classifier\"\n",
    "\n",
    "print(f\"ðŸ¥‡ Registering the {best_run['params.model_type']} (Run ID: {run_id})\")\n",
    "\n",
    "# 2. Register to Unity Catalog\n",
    "model_version = mlflow.register_model(model_uri=model_uri, name=model_name)\n",
    "\n",
    "# 3. (Optional) Set an alias so your 'Rising Stars' report always uses this version\n",
    "from mlflow import MlflowClient\n",
    "client = MlflowClient()\n",
    "client.set_registered_model_alias(model_name, \"champion\", model_version.version)\n",
    "\n",
    "print(f\"âœ… Success! Model is now live in Unity Catalog as '{model_name}' version {model_version.version}\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Day 3 ML Flow",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
