{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b8d78585-b15a-4c2a-a45e-3c3b4d823f9b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#ML Prep (Feature engineering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "37547d2e-9fb8-47d5-8eb3-2e51c95bda71",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "df = spark.table(\"workspace.ecommerce.mlPrepGold\")\n",
    "\n",
    "# Check for skewness in revenue and purchase rates\n",
    "df.select(\"v2p_rate\", \"total_revenue\", \"price_mean\").summary().show()\n",
    "\n",
    "# Find high-value products that might be outliers (Z-Score logic)\n",
    "price_stats = df.select(F.mean(\"price_mean\").alias(\"avg\"), F.stddev(\"price_mean\").alias(\"std\")).collect()\n",
    "avg_p, std_p = price_stats[0]['avg'], price_stats[0]['std']\n",
    "\n",
    "outliers = df.filter(F.col(\"price_mean\") > (avg_p + 3 * std_p))\n",
    "print(f\"Number of price outliers: {outliers.count()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0e8df23c-ba82-42e2-a33e-4d870a29b426",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Top 10% revenue Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4f645c50-3b5a-48c2-9225-c673a93b50a1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Find the 90th percentile value for total_revenue\n",
    "threshold_value = df.approxQuantile(\"total_revenue\", [0.9], 0.01)[0]\n",
    "print(f\"Top 10% Revenue Threshold: ${threshold_value:.2f}\")\n",
    "\n",
    "# Create the binary 'label' (1 for Top Seller, 0 for others)\n",
    "df_labeled = df.withColumn(\"is_top_seller\", \n",
    "                           F.when(F.col(\"total_revenue\") >= threshold_value, 1).otherwise(0))\n",
    "\n",
    "# Quick check: How many Top Sellers do we have?\n",
    "df_labeled.groupBy(\"is_top_seller\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5af6006c-2e8c-4dc1-a342-c71966e2b7a8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Filters views > 100 |  view_to_purchase_rate > 50% threshold "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8dde1a7d-932b-401a-b797-dd814039f758",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Apply the stricter filters for high-quality signal\n",
    "df_high_intent = df_labeled.filter((F.col(\"total_views\") > 100) & (F.col(\"v2p_rate\")>0.01) )\n",
    "\n",
    "# Check how many products remain\n",
    "print(f\"Remaining products for training: {df_high_intent.count()}\")\n",
    "df_high_intent.groupBy(\"is_top_seller\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d073b591-7e84-4aac-9148-e7ccc3dffbda",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Imputer\n",
    "\n",
    "# Define columns that might have nulls\n",
    "input_cols = [\"total_views\", \"v2p_rate\", \"price_mean\", ]\n",
    "output_cols = [f\"{c}_imputed\" for c in input_cols]\n",
    "\n",
    "# Initialize and fit the Imputer\n",
    "imputer = Imputer(inputCols=input_cols, outputCols=output_cols).setStrategy(\"median\")\n",
    "df_final_prep = imputer.fit(df_high_intent).transform(df_high_intent)\n",
    "\n",
    "print(\"Nulls handled. Ready for final model registration.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "d8c35270-be6e-4e03-b709-ea3b51d02f94",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "display(\n",
    "    df_final_prep.filter(\n",
    "        F.col(\"total_views_imputed\").isNull() | (F.col(\"total_views\") == 0) |\n",
    "        #F.col(\"total_carts\").isNull() | (F.col(\"total_carts\") == 0) |\n",
    "        F.col(\"v2p_rate_imputed\").isNull() | (F.col(\"v2p_rate\") == 0) |\n",
    "        #F.col(\"cart_to_purchase_rate\").isNull() | (F.col(\"cart_to_purchase_rate\") == 0) |\n",
    "        F.col(\"price_mean_imputed\").isNull() | (F.col(\"price_mean\") == 0)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ff8ca248-c751-491b-be08-3f18fc95de9a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_final_prep.write.mode(\"overwrite\").saveAsTable(\"workspace.ecommerce.mlPrepFeatures\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "87ce22d5-434d-4271-9247-6d3e4b535bce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "\n",
    "ALTER TABLE workspace.ecommerce.mlPrepFeatures\n",
    "ALTER COLUMN product_id SET NOT NULL;\n",
    "\n",
    "ALTER TABLE workspace.ecommerce.mlPrepFeatures ADD CONSTRAINT prepfeatures_pk PRIMARY KEY (product_id);\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 7969884635217075,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Day 3 MLPrep",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
