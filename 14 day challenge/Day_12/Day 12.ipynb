{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bcc6f2fc-0aeb-4511-9c12-8f55838ffb40",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Product level Analysis (More granular) & Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d194e66c-3225-4bd7-9575-9d5c3e732dd6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Already Loaded to Bronze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c6e51988-0da7-4947-a99b-75f2d5293f50",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "events = spark.read.table(\"workspace.ecommerce.df_october\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7753cad7-8a98-4d2e-b147-29cfbaa4da15",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "events = events.withColumn(\"date\",F.col(\"event_time\").cast(\"date\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "44212359-9cf2-4480-9c11-008b2c30f7a6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Bronze to silver (Product conversion ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "629c5dda-1778-4ab8-92bb-8e7bca962509",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "product_agg = (\n",
    "    events\n",
    "    .filter(F.col(\"product_id\").isNotNull())\n",
    "    .groupBy(\"product_id\")\n",
    "    .agg(\n",
    "        F.count(F.when(F.col(\"event_type\") == \"view\", 1)).alias(\"total_views\"),\n",
    "        F.count(F.when(F.col(\"event_type\") == \"cart\", 1)).alias(\"total_carts\"),\n",
    "        F.count(F.when(F.col(\"event_type\") == \"purchase\", 1)).alias(\"total_purchases\"),\n",
    "        F.round(\n",
    "            F.sum(F.when(F.col(\"event_type\") == \"purchase\", F.col(\"price\"))), 2\n",
    "        ).alias(\"total_revenue\")\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8c17e82b-04b8-4c84-9733-8a6cf0dbec96",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "product_features = (\n",
    "    product_agg\n",
    "    .withColumn(\"has_views\", F.col(\"total_views\") > 0)\n",
    "    .withColumn(\"has_carts\", F.col(\"total_carts\") > 0)\n",
    "    .withColumn(\"has_purchases\", F.col(\"total_purchases\") > 0)\n",
    "    .withColumn(\"has_revenue\", F.col(\"total_revenue\") > 0)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7e72f064-019a-426f-879a-9ed7f79f1cef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "product_features = (\n",
    "    product_features\n",
    "    .withColumn(\n",
    "        \"view_to_purchase_rate\",\n",
    "        F.when(F.col(\"total_views\") >= 100,\n",
    "               F.round(F.col(\"total_purchases\") / F.col(\"total_views\"), 4))\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"cart_to_purchase_rate\",\n",
    "        F.when(F.col(\"total_carts\") >= 5,\n",
    "               F.round(F.col(\"total_purchases\") / F.col(\"total_carts\"), 4))\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "145b3cdf-a107-4564-ab32-4c4868ed3b71",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "price_stats = (\n",
    "    events\n",
    "    .filter(F.col(\"product_id\").isNotNull())\n",
    "    .groupBy(\"product_id\")\n",
    "    .agg(\n",
    "        F.count(\"price\").alias(\"price_sample_size\"),\n",
    "        F.round(F.mean(\"price\"), 2).alias(\"price_mean\"),\n",
    "        F.round(F.stddev(\"price\"), 2).alias(\"price_stddev\"),\n",
    "        F.round(F.min(\"price\"), 2).alias(\"price_min\"),\n",
    "        F.round(F.max(\"price\"), 2).alias(\"price_max\")\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "91ef15d0-dcde-4db5-b92d-ac1b88f3bf49",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "product_features = product_features.join(\n",
    "    price_stats, \"product_id\", \"left\"\n",
    ")\n",
    "\n",
    "\n",
    "product_features = (\n",
    "    product_features\n",
    "    .withColumn(\"feature_generated_at\", F.current_timestamp())\n",
    "    .withColumn(\"source_window\", F.lit(\"october_2023\"))\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "97f9538e-33e5-49aa-a972-5513cae74ff0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "pk_check = (\n",
    "    product_features\n",
    "    .groupBy(\"product_id\")\n",
    "    .count()\n",
    "    .filter(\"count > 1\")\n",
    ")\n",
    "\n",
    "if pk_check.count() > 0:\n",
    "    pk_check.display()\n",
    "    raise Exception(\"Primary key violation: product_id\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6af5c143-9344-47a1-b6ee-ccb24f3e33a3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Silver to Gold (stats added)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "948cacf2-6d59-47f6-a580-67506a55ae88",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "product_features.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"overwriteSchema\", \"true\") \\\n",
    "    .saveAsTable(\"ecom.gold.product_features\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2332475d-bb8c-4559-ac8a-26275a5fdb4c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "\n",
    "ALTER TABLE ecom.gold.product_features\n",
    "ALTER COLUMN product_id SET NOT NULL;\n",
    "\n",
    "ALTER TABLE ecom.gold.product_features ADD CONSTRAINT product_features_pk PRIMARY KEY (product_id);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8fa16591-2413-4a19-9bc0-0367cd1b734c",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1768912475428}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(spark.read.table(\"ecom.gold.product_features\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "85f14e09-0420-4f50-b997-3a2dacffc842",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "d = spark.read.table(\"ecom.gold.product_features\")\n",
    "                     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c55409b4-9f9b-4c1d-81ea-e7c4d4fd2834",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cc5c8025-b9df-47bd-b683-19c399d3440f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4ec25fcd-64c4-47d4-8384-dea07fa5e4bb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "df = spark.table(\"ecom.gold.product_features\")\n",
    "\n",
    "# Check for skewness in revenue and purchase rates\n",
    "df.select(\"view_to_purchase_rate\", \"total_revenue\", \"price_mean\").summary().show()\n",
    "\n",
    "# Find high-value products that might be outliers (Z-Score logic)\n",
    "price_stats = df.select(F.mean(\"price_mean\").alias(\"avg\"), F.stddev(\"price_mean\").alias(\"std\")).collect()\n",
    "avg_p, std_p = price_stats[0]['avg'], price_stats[0]['std']\n",
    "\n",
    "outliers = df.filter(F.col(\"price_mean\") > (avg_p + 3 * std_p))\n",
    "print(f\"Number of price outliers: {outliers.count()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cdadc267-caca-4657-91db-a44e82fdad1b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Strict filtering for Outlier | Top 10% revenue Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0444a97e-b2dd-46c6-8e63-d84616638b95",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Find the 90th percentile value for total_revenue\n",
    "threshold_value = df.approxQuantile(\"total_revenue\", [0.9], 0.01)[0]\n",
    "print(f\"Top 10% Revenue Threshold: ${threshold_value:.2f}\")\n",
    "\n",
    "# Create the binary 'label' (1 for Top Seller, 0 for others)\n",
    "df_labeled = df.withColumn(\"is_top_seller\", \n",
    "                           F.when(F.col(\"total_revenue\") >= threshold_value, 1).otherwise(0))\n",
    "\n",
    "# Quick check: How many Top Sellers do we have?\n",
    "df_labeled.groupBy(\"is_top_seller\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d4f559b1-6729-49ba-a12c-79dc73a761bf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Filters views > 100 | Added to cart > 5 | view_to_purchase_rate > 75% threshold | cart_to_purchase_rate > 25% threshold (this will handle Nulls too)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "51075272-d7c8-41fe-bfdf-ffb42c4db11b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Apply the stricter filters for high-quality signal\n",
    "df_high_intent = df_labeled.filter((F.col(\"total_views\") > 100) & (F.col(\"total_carts\") > 5) & (F.col(\"view_to_purchase_rate\")>0.01) &  (F.col(\"cart_to_purchase_rate\")> 0.4))\n",
    "\n",
    "# Check how many products remain\n",
    "print(f\"Remaining products for training: {df_high_intent.count()}\")\n",
    "df_high_intent.groupBy(\"is_top_seller\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e6c3fcbe-75bd-4c4c-9e1c-5713686a9f3c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Building Vector Assembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8e79b773-8053-4d37-9afc-2e3e4d4ea029",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "# Prep the features (similar to before, but adding the new label)\n",
    "feature_cols = [\"total_views\", \"total_carts\", \"view_to_purchase_rate\", \"cart_to_purchase_rate\", \"price_mean\"]\n",
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b12bda9b-4f01-4c11-bdbd-a4cab3a4678b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "ML Model (GBT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9d91b577-ce2f-4383-904a-c64401f6f956",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import GBTClassifier\n",
    "\n",
    "# 1. Re-run the Assembler on the new filtered data\n",
    "X_train, X_test = df_high_intent.randomSplit([0.8, 0.2], seed=42)\n",
    "train_data = assembler.transform(X_train)\n",
    "\n",
    "# 2. Train a GBT Model\n",
    "gbt = GBTClassifier(labelCol=\"is_top_seller\", featuresCol=\"features\", maxIter=10)\n",
    "gbt_model = gbt.fit(train_data)\n",
    "\n",
    "# 3. View the new \"Clean\" Importance\n",
    "importances = gbt_model.featureImportances\n",
    "for feature, importance in zip(feature_cols, importances):\n",
    "    print(f\"Feature: {feature:25} Importance: {importance:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9d963924-980c-4d7f-ae0d-26a415d31139",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Training Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "07fc1845-a0c8-43ce-b884-dd09e12be750",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.spark\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "dfs_tmp_path = \"/Volumes/workspace/ecommerce/ecommerce_data\"\n",
    "\n",
    "# Start the MLflow experiment\n",
    "with mlflow.start_run(run_name=\"Elite_Product_Classifier\") as run:\n",
    "    \n",
    "    # 1. Log the Threshold Parameters you chose\n",
    "    mlflow.log_param(\"min_views\", 100)\n",
    "    mlflow.log_param(\"min_carts\", 5)\n",
    "    mlflow.log_param(\"v2p_threshold\", 0.01)\n",
    "    mlflow.log_param(\"c2p_threshold\", 0.4)\n",
    "    \n",
    "    # 2. Train the Model (already defined in your previous step)\n",
    "    # gbt_model = gbt.fit(train_data)\n",
    "    \n",
    "    # 3. Log Model & Metrics\n",
    "    #mlflow.spark.log_model(gbt_model, \"gbt_product_model\")\n",
    "\n",
    "    # Updated log_model with the dfs_tmpdir argument\n",
    "    mlflow.spark.log_model(\n",
    "        spark_model=gbt_model, \n",
    "        artifact_path=\"gbt-model\",\n",
    "        dfs_tmpdir=dfs_tmp_path # This satisfies the UC Volume requirement\n",
    "    )\n",
    "    \n",
    "    # Calculate and log Accuracy (AUC)\n",
    "    predictions = gbt_model.transform(assembler.transform(X_test))\n",
    "    evaluator = BinaryClassificationEvaluator(labelCol=\"is_top_seller\")\n",
    "    auc = evaluator.evaluate(predictions)\n",
    "    mlflow.log_metric(\"auc_roc\", auc)\n",
    "    \n",
    "    # Log Feature Importances\n",
    "    for feature, importance in zip(feature_cols, importances):\n",
    "        mlflow.log_metric(f\"importance_{feature}\", importance)\n",
    "        \n",
    "    print(f\"Model logged successfully! AUC: {auc:.4f}\")\n",
    "    run_id = run.info.run_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b5c4bfab-cc14-4a56-9dfc-ccdcb01d8758",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "MLFlow Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a6c70cee-6465-43c8-a3c1-70f3decd2460",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.spark\n",
    "from mlflow.models.signature import infer_signature\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "# Define your Unity Catalog Volume path for SparkML checkpointing\n",
    "dfs_tmp_path = \"/Volumes/workspace/ecommerce/ecommerce_data\"\n",
    "\n",
    "with mlflow.start_run(run_name=\"Elite_Product_Classifier_Final\") as run:\n",
    "    \n",
    "    # 1. Log Business Logic Parameters (Thresholds)\n",
    "    mlflow.log_params({\n",
    "        \"min_views\": 100,\n",
    "        \"min_carts\": 5,\n",
    "        \"v2p_threshold\": 0.01,\n",
    "        \"c2p_threshold\": 0.4\n",
    "    })\n",
    "    \n",
    "    # 2. Create a Model Signature (Critical for Unity Catalog)\n",
    "    # We use a sample of our training features to define the schema\n",
    "    input_example = X_train.select(feature_cols).limit(5).toPandas()\n",
    "    output_example = gbt_model.transform(assembler.transform(X_train)).select(\"prediction\").limit(5).toPandas()\n",
    "    signature = infer_signature(input_example, output_example)\n",
    "    \n",
    "    # 3. Log the Model with Signature and Volume Path\n",
    "    mlflow.spark.log_model(\n",
    "        spark_model=gbt_model, \n",
    "        artifact_path=\"gbt-model\",\n",
    "        dfs_tmpdir=dfs_tmp_path,\n",
    "        signature=signature,\n",
    "        input_example=input_example\n",
    "    )\n",
    "    \n",
    "    # 4. Evaluate and Log Performance Metrics\n",
    "    predictions = gbt_model.transform(assembler.transform(X_test))\n",
    "    evaluator = BinaryClassificationEvaluator(labelCol=\"is_top_seller\")\n",
    "    auc = evaluator.evaluate(predictions)\n",
    "    mlflow.log_metric(\"auc_roc\", auc)\n",
    "    \n",
    "    # 5. Log Feature Importances for Audit\n",
    "    for feature, importance in zip(feature_cols, importances):\n",
    "        mlflow.log_metric(f\"importance_{feature}\", importance)\n",
    "        \n",
    "    print(f\"âœ… Model logged successfully!\")\n",
    "    print(f\"ðŸ“Š AUC-ROC: {auc:.4f}\")\n",
    "    print(f\"ðŸš€ Run ID: {run.info.run_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ffeb26ca-c51a-4471-8a1d-19f7b5bcc1d7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Model Registered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dcd540e0-1d8d-4fe1-9abb-fa03890be172",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define the Model Name in Unity Catalog format: <catalog>.<schema>.<model_name>\n",
    "model_name = \"workspace.ecommerce.elite_product_classifier\"\n",
    "\n",
    "# Register the model using the Run ID from the previous step\n",
    "model_uri = f\"runs:/{run.info.run_id}/gbt-model\"\n",
    "registered_model = mlflow.register_model(model_uri, model_name)\n",
    "\n",
    "print(f\"âœ… Model registered as: {model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "61699b7a-c5b0-4bd7-b796-8c3a207665d8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Rising Star (Products) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aeafa358-fa78-43db-becd-2fe9ed688cfa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.functions import vector_to_array\n",
    "\n",
    "# 1. Load the model back (using the 'latest' version)\n",
    "\n",
    "model_name = \"workspace.ecommerce.elite_product_classifier\"\n",
    "dfs_tmp_path = \"/Volumes/workspace/ecommerce/ecommerce_data\"\n",
    "\n",
    "loaded_model = mlflow.spark.load_model(f\"models:/{model_name}/1\", dfs_tmpdir=dfs_tmp_path)\n",
    "\n",
    "# 2. Score all high-intent products\n",
    "scored_df = loaded_model.transform(assembler.transform(df_high_intent))\n",
    "\n",
    "# 3. Filter for products the model loves (>80% prob) but aren't Top Sellers yet\n",
    "rising_stars_final = (\n",
    "    scored_df\n",
    "    .withColumn(\"success_probability\", vector_to_array(\"probability\")[1])\n",
    "    .filter((F.col(\"is_top_seller\") == 0) & (F.col(\"success_probability\") > 0.8))\n",
    "    .select(\n",
    "        \"product_id\", \n",
    "        \"total_views\", \n",
    "        \"total_revenue\", \n",
    "        F.round(\"success_probability\", 4).alias(\"prob_score\"),\n",
    "        \"price_mean\"\n",
    "    )\n",
    "    .orderBy(F.col(\"success_probability\").desc())\n",
    ")\n",
    "\n",
    "# 4. Save to a Gold table for Business Teams\n",
    "rising_stars_final.write.mode(\"overwrite\").saveAsTable(\"workspace.ecommerce.rising_stars_report\")\n",
    "\n",
    "print(\"ðŸš€ Rising Stars table created!\")\n",
    "display(rising_stars_final.limit(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "99e891a9-b264-41bb-93bc-7adcb10ebb0d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 5245675820230184,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Day 12",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
